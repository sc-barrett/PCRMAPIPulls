{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89602af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f1cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd6d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_dataframe(df):\n",
    "    \"\"\"\n",
    "    Ensures that a dataframes columns are consistent for merging and for sql datatypes\n",
    "    Parameters\n",
    "    ---------\n",
    "    df : dataframe\n",
    "        a dataframe whose columns you want to adjust\n",
    "    Returns\n",
    "    df : dataframe\n",
    "        a dataframe with adjusted columns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    def convert_id(row):\n",
    "        try:\n",
    "            new_id = int(float(row))\n",
    "        except:\n",
    "            new_id = row\n",
    "        return new_id\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    df = df.replace('NaN', np.nan)\n",
    "    df = df.fillna(value=np.nan)\n",
    "    for col in df.columns:\n",
    "        if col in ['asof_date', 'Date', 'date', 'dates']:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "        if col in ['id', 'external_id', 'fundId', 'Fund_ID', 'Index_ID', 'external_strategy_id', 'strategy_code', 'strategy_fund_id', 'Fund ID', 'Firm_ID', 'Firm ID', 'ret_ts_id', 'aum_ts_id', 'id_record_number', 'risk_ts_id']:\n",
    "            try:\n",
    "                df[col] = df[col].apply(int)\n",
    "\n",
    "            except:  # if there are np.nan's in the column, apply(int) fails - this is a workaround\n",
    "                df[col] = df[col].astype('object')\n",
    "\n",
    "            for index, row in df.iterrows():\n",
    "                df.loc[index, col] = convert_id(df.loc[index, col])\n",
    "    return df\n",
    "\n",
    "\n",
    "#delete if return value new = return value old\n",
    "def batch_delete(list_to_delete, table_name, delete_column_name):\n",
    "    \"\"\"\n",
    "    Deletes a list of records from a given database table, given a column name\n",
    "        Validates the data to add proper quotations based on the first item in the list\n",
    "        Also checks to see how many records are being deleted and will batch delete if necessary\n",
    "    Parameters\n",
    "    ---------\n",
    "    list_to_delete : list\n",
    "        a list of items, each denoting one row, that will be deleted\n",
    "        each item in the list should be one unique row\n",
    "    table_name: string\n",
    "        the name of the table to delete from\n",
    "    delete_column_name: string\n",
    "        the name of the column in <table_name> to delete the items from <list_to_delete>\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    from sqlalchemy.engine import URL\n",
    "    from sqlalchemy import create_engine\n",
    "    from math import ceil\n",
    "    from pyodbc import connect\n",
    "    import pandas as pd\n",
    "    connection_string = 'Driver={SQL Server};Server=scdb1.silvercreeksv.com;Database=scfundrisk;Trusted_Connection=yes;'\n",
    "    connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "\n",
    "    engine = create_engine(connection_url)\n",
    "    conn = connect(connection_string)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    if type(list_to_delete) is not list:\n",
    "        raise ValueError(\"\"\"'list_to_delete' must be of type list \"\"\")\n",
    "    # get initial record count\n",
    "    beg_no_records_df = pd.read_sql_query(\"\"\"select count(\"\"\"+delete_column_name+\"\"\") as ct from \"\"\"+table_name, engine)\n",
    "    no_records = beg_no_records_df.loc[0, 'ct']\n",
    "    if len(list_to_delete) > 0:\n",
    "        # the database can only delete 2090 records in one go\n",
    "        # if number of records>2090, we have to beak it up\n",
    "        if len(list_to_delete) > 2090:\n",
    "            print('need to batch delete to accomodate database limits')\n",
    "            num_iterations = ceil(len(list_to_delete)/2090)\n",
    "            for i in range(num_iterations):\n",
    "                print('deleting rows '+str(i*2090)+' to '+str(min(2090*(i+1), len(list_to_delete))))\n",
    "                sub_list_to_delete = list_to_delete[2090*(i):2090*(i+1)]\n",
    "                if type(sub_list_to_delete[0]) == str:\n",
    "                    # we only check the first element because sql ensures constant datatypes\n",
    "                    sub_list_to_delete = \"','\".join((map(str, sub_list_to_delete)))\n",
    "                    sub_list_to_delete = \"'\"+sub_list_to_delete+\"'\"\n",
    "                else:\n",
    "                    sub_list_to_delete = ','.join((map(str, sub_list_to_delete)))\n",
    "                sub_list_to_delete = '('+sub_list_to_delete+')'\n",
    "                cursor.execute(''' DELETE FROM '''+table_name+''' where '''+delete_column_name+''' in '''+sub_list_to_delete)\n",
    "                conn.commit()\n",
    "\n",
    "        elif len(list_to_delete) > 0:\n",
    "            if type(list_to_delete[0]) == str:\n",
    "                # we only check the first element because sql ensures constant datatypes\n",
    "                temp_list_to_delete = \"','\".join((map(str, list_to_delete)))\n",
    "                temp_list_to_delete = \"'\"+temp_list_to_delete+\"'\"\n",
    "            else:\n",
    "                temp_list_to_delete = ','.join((map(str, list_to_delete)))\n",
    "            temp_list_to_delete = '('+temp_list_to_delete+')'\n",
    "            cursor.execute(''' DELETE FROM '''+table_name+''' where '''+delete_column_name+''' in '''+temp_list_to_delete)\n",
    "            conn.commit()\n",
    "        # get updated record count\n",
    "        end_no_records_df = pd.read_sql_query(\"\"\"select count(\"\"\"+delete_column_name+\"\"\") as ct from \"\"\"+table_name, engine)\n",
    "        end_no_records = end_no_records_df.loc[0, 'ct']\n",
    "        print('deleted '+str(no_records-end_no_records)+' number of records from table: '+table_name+', based on column: ' + delete_column_name)\n",
    "    else:\n",
    "        print('no records to delete from: '+table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77897d71",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Download S&P US LLI from SFTP  \n",
    "import datetime  \n",
    "import paramiko\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import xlrd\n",
    "now = datetime.datetime.now()\n",
    "year = now.strftime(\"%Y\")\n",
    "month = now.strftime(\"%#m\")\n",
    "#server = 'lcdx.pitchbook.com'\n",
    "    # server_ip=3.130.0.55\n",
    "\n",
    "ssh_client = paramiko.SSHClient()\n",
    "\n",
    "\n",
    "server = 'sftp.lcdx.pitchbook.com'\n",
    "port = 22\n",
    "user = 'SilverCreek'\n",
    "password = '4E~l#4qH'\n",
    "\n",
    "\n",
    "ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "ssh_client.connect(server,port,user,password)\n",
    "ssh_client = ssh_client.open_sftp()\n",
    "remotepath = '/Inbox/Returns Summary-'+month+'-' +year+'.xls'\n",
    "localpath='//seanas.silvercreeksv.com/shared drive/Investments/Investment Process/Tools/Data Ingestion/LCD/Raw Data/LCDMostRecent.xls'\n",
    "ssh_client.get(remotepath, localpath)\n",
    "\n",
    "#GICS III\n",
    "\n",
    "xls = pd.ExcelFile('//seanas.silvercreeksv.com/shared drive/Investments/Investment Process/Tools/Data Ingestion/LCD/Raw Data/LCDMostRecent.xls') \n",
    "df1 = pd.read_excel(xls,'GICS III Returns' )\n",
    "# read by default 1st sheet of an excel file\n",
    "df1 = df1.iloc[12:]\n",
    "df2 = df1.dropna(how='all')\n",
    "\n",
    "df3 = df2.dropna(how='all',axis=1)\n",
    "df4 = df3.dropna(thresh = 10)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df5 = df4.rename(columns = {'Unnamed: 0': 'Date'})\n",
    "df5['Date'] = pd.to_datetime(df5['Date'])\n",
    "df6 = df5.sort_values(by='Date', ascending = True)\n",
    "#df6.head(10)\n",
    "\n",
    "#obtain LLI Rating Returns\n",
    "dfa1 = pd.read_excel(xls, \"Monthly\")\n",
    "dfa2 = dfa1.dropna(how='all')\n",
    "dfa3 = dfa2.dropna(how='all',axis=1)\n",
    "#dfa3['Date'] = pd.to_datetime(dfa3['Date'])\n",
    "dfa4 = dfa3.sort_values(by='Date', ascending = True)\n",
    "dfa5 = dfa4[['Date','BBB Index','BB Index', 'B Index','BB/B Index', 'CCC Only Index']]\n",
    "\n",
    "\n",
    "#merge\n",
    "df7 = pd.merge(df6, dfa5,left_on = 'Date',right_on = 'Date',how = 'left')\n",
    "df7.columns = ['LLI- ' + str(col) for col in df7.columns]\n",
    "df8LLI = df7.rename(columns={'LLI- Date': 'Date'})\n",
    "#df8LLI.to_excel('//seanas.silvercreeksv.com/shared drive/Investments/Investment Process/Tools/Data Ingestion/LCD/LLI_GICS_Cleaned.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503515ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ELLI download off SFTP\n",
    "import datetime  \n",
    "import paramiko\n",
    "    #import keyring \n",
    "now = datetime.datetime.now()\n",
    "year = now.strftime(\"%Y\")\n",
    "month = now.strftime(\"%#m\")\n",
    "\n",
    "\n",
    "ssh_client = paramiko.SSHClient()\n",
    "\n",
    "server = 'sftp.lcdx.pitchbook.com'\n",
    "    # server_ip=3.130.0.55\n",
    "port = 22\n",
    "user = 'SilverCreek'\n",
    "\n",
    "password='4E~l#4qH'\n",
    "\n",
    "ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "ssh_client.connect(server,port,user,password)\n",
    "ssh_client = ssh_client.open_sftp()\n",
    "remotepath = '/Inbox/ELLI Returns Summary.xlsx'\n",
    "localpath='//seanas.silvercreeksv.com/shared drive/Investments/Investment Process/Tools/Data Ingestion/LCD/Raw Data/ELLIMostRecent.xls'\n",
    "ssh_client.get(remotepath, localpath)\n",
    "\n",
    "#ELLI Clean and Export\n",
    "import pandas as pd\n",
    "import datetime\n",
    "xls = pd.ExcelFile('//seanas.silvercreeksv.com/shared drive/Investments/Investment Process/Tools/Data Ingestion/LCD/Raw Data/ELLIMostRecent.xls') \n",
    "df1 = pd.read_excel(xls,'GICS III Returns' )\n",
    "# read by default 1st sheet of an excel file\n",
    "df1 = df1.iloc[12:]\n",
    "df2 = df1.dropna(how='all')\n",
    "\n",
    "df3 = df2.dropna(how='all',axis=1)\n",
    "df4 = df3.dropna(thresh = 10)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df5 = df4.rename(columns = {'Unnamed: 0': 'Date'})\n",
    "df5['Date'] = pd.to_datetime(df5['Date'])\n",
    "df6 = df5.sort_values(by='Date', ascending = True)\n",
    "\n",
    "\n",
    "#obtain ELLI Rating Returns\n",
    "dfa1 = pd.read_excel(xls, \"Monthly\")\n",
    "dfa2 = dfa1.dropna(how='all')\n",
    "dfa3 = dfa2.dropna(how='all',axis=1)\n",
    "#dfa3['Date'] = pd.to_datetime(dfa3['Date'])\n",
    "dfa4 = dfa3.sort_values(by='Date', ascending = True)\n",
    "dfa5 = dfa4[['Date','BB Loans', 'B Loans', 'CCC Loans']]\n",
    "\n",
    "#merge\n",
    "df7 = pd.merge(df6, dfa5,left_on = 'Date',right_on = 'Date',how = 'left')\n",
    "df7.columns = ['ELLI- ' + str(col) for col in df7.columns]\n",
    "df8ELLI = df7.rename(columns={'ELLI- Date': 'Date'})\n",
    "# df8ELLI.to_excel('//seanas.silvercreeksv.com/shared drive/Investments/Investment Process/Tools/Data Ingestion/LCD/ELLI_GICS_Cleaned.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be26b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "from math import ceil\n",
    "from pyodbc import connect\n",
    "import pandas as pd\n",
    "connection_string = 'Driver={SQL Server};Server=scdb1.silvercreeksv.com;Database=scfundrisk;Trusted_Connection=yes;'\n",
    "connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "engine = create_engine(connection_url)\n",
    "conn = connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "#merge for all\n",
    "\n",
    "dfAll = pd.merge(df8ELLI, df8LLI,left_on = 'Date', right_on = 'Date', how = 'left')\n",
    "dfAll.head(10)\n",
    "# dfAll.to_excel('//seanas.silvercreeksv.com/shared drive/Investments/Investment Process/Tools/Data Ingestion/LCD/All_GICS_Cleaned.xlsx', index = False)\n",
    "\n",
    "#Backfill\n",
    "# bf = pd.read_excel('//seanas.silvercreeksv.com/shared drive/Investments/PC Risk/8. Working Files/AB working files/GICSBackfill.xlsx')\n",
    "# seriesconcat = [dfAll]\n",
    "# dfAllBackfilled = pd.concat(seriesconcat)\n",
    "# dfAllBackfilled.to_excel(\"GICS test 3.xlsx\")\n",
    "FUSEinputLLI = pd.melt(dfAll, id_vars = \"Date\")\n",
    "\n",
    "\n",
    "#error handling to account for new proxies, or proxies being taken away\n",
    "# import pandas as pd\n",
    "# from sqlalchemy.engine import URL\n",
    "# from sqlalchemy import create_engine, inspect\n",
    "# connection_string ='Driver={SQL Server};Server=scdb1.silvercreeksv.com;Database=scfundrisk;Trusted_Connection=yes;'\n",
    "# connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "# engine = create_engine(connection_url)\n",
    "# #count how many proxies are coming from the current source to match with what's being pulled\n",
    "# df = pd.read_sql_query(\"SELECT * FROM benchmarks WHERE benchmarks.benchmark_type = 'pc-risk' AND benchmarks.benchmark_source = 'lcd'\", engine)\n",
    "# #count number of columns in S&P download subtracting dates column\n",
    "# cols = len(dfAll.axes[1]) - 1\n",
    "# if len(df['benchmark_name']) != cols:\n",
    "# \traise ValueError(\"The number of proxies being downloaded does not equal the amount in DB\")\n",
    "# #error handling to account for change in proxy spelling\n",
    "# #proxies alphabetized from data download\n",
    "# edf = FUSEinputLLI[['Proxy']]\n",
    "# edf = edf.drop_duplicates(keep = 'first')\n",
    "# edf.sort_values('Proxy')\n",
    "# #proxies alphabetized from DB\n",
    "# dbdf = df[['benchmark_name']].sort_values('benchmark_name')\n",
    "# for i in range(len(df)):\n",
    "#     if edf.iloc[i,0] != dbdf.iloc[i,0]:\n",
    "#         raise ValueError(\"The names of the proxies do not match\")\n",
    "\n",
    "\n",
    "\n",
    "#rename columns and drop nulls\n",
    "FUSEinputLLI.rename(columns = {'variable':'Proxy', 'value':'return_value', 'Date': 'asof_date' }, inplace = True)\n",
    "FUSEinputLLI = FUSEinputLLI.replace('NA', np.nan)\n",
    "FUSEinputLLI = FUSEinputLLI.dropna()\n",
    "\n",
    "\n",
    "\n",
    "#pull in benchmark ID, and replace name with ID for DB upload\n",
    "\n",
    "lookupid = pd.read_sql_query(\"select * from benchmarks where benchmark_source = 'lcd'\",engine)\n",
    "FUSEinputLLI = adj_dataframe(FUSEinputLLI)\n",
    "lookupid = adj_dataframe(lookupid)\n",
    "dffinale = FUSEinputLLI.merge(lookupid[[\"benchmark_id\",\"benchmark_name\"]], how = \"left\", left_on = \"Proxy\", right_on = \"benchmark_name\", suffixes = (\" new\", \" old\"))\n",
    "dffinale = dffinale[[\"asof_date\", \"return_value\", \"benchmark_id\"]]\n",
    "dffinale['return_value'] = dffinale['return_value'].apply(lambda row: round(row, 15))\n",
    "\n",
    "#pull in what's already in the database NEED TO CHANGE TO INCLUDE 'BENCHMARK-LCD'\n",
    "dffinal = pd.read_sql_query(\"SELECT * FROM benchmark_returns_ts WHERE benchmark_id IN (SELECT benchmark_id from benchmarks WHERE benchmark_source = 'lcd')\",engine)\n",
    "\n",
    "#run function that adjusts column types to make them the same\n",
    "dffinale = adj_dataframe(dffinale)\n",
    "dffinal = adj_dataframe(dffinal)\n",
    "\n",
    "#merge the two\n",
    "dfinput = dffinale.merge(dffinal, how = \"left\", on = [\"benchmark_id\",\"asof_date\"], suffixes = (\" new\", \" old\"))\n",
    "dfinput = adj_dataframe(dfinput)\n",
    "\n",
    "\n",
    "#WRITE CODE TO CHECK IF NEW = OLD, IF SO THEN SKIP, IF NOT THEN REPLACE\n",
    "\n",
    "#create a new column checking that new value is equal to the old\n",
    "dfinput['matching'] = dfinput.apply(lambda x: x['return_value new'] == x['return_value old'], axis=1)\n",
    "\n",
    "#create a new df with just values that do not match to delete from DB\n",
    "dfdelete = dfinput[dfinput[\"matching\"] == False]\n",
    "valstodelete = list[dfdelete['ret_ts_id']] #may want to delete the ret_ts_id\n",
    "# batch_delete(valstodelete,'benchmark_return_ts', 'ret_ts_id')\n",
    "\n",
    "dfnewinput = dfinput[dfinput['ret_ts_id'].isnull()]\n",
    "\n",
    "dfallcombined = pd.concat([dfdelete, dfnewinput])\n",
    "\n",
    "#clean dfallcombined for same columns as in database\n",
    "\n",
    "\n",
    "dffinalinput = dfallcombined[[\"asof_date\",\"return_value new\", \"source\",\"type\"]] #HOW WILL IT KNOW THE SOURCE? IS RET_TS_ID AUTOFILLED?\n",
    "dffinalinput = dffinalinput.rename(columns = {'return_value new':'return_value'})\n",
    "\n",
    "#dffinalinput.to_sql('benchmark_returns_ts', engine, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# dfinput\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0820114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asof_date</th>\n",
       "      <th>return_value</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [asof_date, return_value, source, type]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffinalinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc00bca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asof_date</th>\n",
       "      <th>return_value new</th>\n",
       "      <th>benchmark_id</th>\n",
       "      <th>return_value old</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>ret_ts_id</th>\n",
       "      <th>matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [asof_date, return_value new, benchmark_id, return_value old, source, type, ret_ts_id, matching]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfallcombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e2d1600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asof_date</th>\n",
       "      <th>return_value new</th>\n",
       "      <th>benchmark_id</th>\n",
       "      <th>return_value old</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>ret_ts_id</th>\n",
       "      <th>matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [asof_date, return_value new, benchmark_id, return_value old, source, type, ret_ts_id, matching]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdelete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47928e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asof_date</th>\n",
       "      <th>return_value new</th>\n",
       "      <th>benchmark_id</th>\n",
       "      <th>return_value old</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>ret_ts_id</th>\n",
       "      <th>matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>371</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415261</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>-0.007770</td>\n",
       "      <td>371</td>\n",
       "      <td>-0.007770</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415262</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>-0.184476</td>\n",
       "      <td>371</td>\n",
       "      <td>-0.184476</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415263</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>0.122415</td>\n",
       "      <td>371</td>\n",
       "      <td>0.122415</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415264</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>371</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415265</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>468</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2443192</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>-0.023635</td>\n",
       "      <td>468</td>\n",
       "      <td>-0.023635</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2443193</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>-0.009448</td>\n",
       "      <td>468</td>\n",
       "      <td>-0.009448</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2443194</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>-0.002857</td>\n",
       "      <td>468</td>\n",
       "      <td>-0.002857</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2443195</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>468</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2443196</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3528 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      asof_date  return_value new  benchmark_id  return_value old source  \\\n",
       "0    2020-01-31          0.001852           371          0.001852    lcd   \n",
       "1    2020-02-29         -0.007770           371         -0.007770    lcd   \n",
       "2    2020-03-31         -0.184476           371         -0.184476    lcd   \n",
       "3    2020-04-30          0.122415           371          0.122415    lcd   \n",
       "4    2020-05-31          0.011719           371          0.011719    lcd   \n",
       "...         ...               ...           ...               ...    ...   \n",
       "3523 2022-08-31          0.009380           468          0.009380    lcd   \n",
       "3524 2022-09-30         -0.023635           468         -0.023635    lcd   \n",
       "3525 2022-10-31         -0.009448           468         -0.009448    lcd   \n",
       "3526 2022-11-30         -0.002857           468         -0.002857    lcd   \n",
       "3527 2022-12-31         -0.008308           468         -0.008308    lcd   \n",
       "\n",
       "      type ret_ts_id  matching  \n",
       "0      NaN   2415261      True  \n",
       "1      NaN   2415262      True  \n",
       "2      NaN   2415263      True  \n",
       "3      NaN   2415264      True  \n",
       "4      NaN   2415265      True  \n",
       "...    ...       ...       ...  \n",
       "3523   NaN   2443192      True  \n",
       "3524   NaN   2443193      True  \n",
       "3525   NaN   2443194      True  \n",
       "3526   NaN   2443195      True  \n",
       "3527   NaN   2443196      True  \n",
       "\n",
       "[3528 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acf76c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asof_date</th>\n",
       "      <th>return_value new</th>\n",
       "      <th>benchmark_id</th>\n",
       "      <th>return_value old</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>ret_ts_id</th>\n",
       "      <th>matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>371</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415261</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>-0.007770</td>\n",
       "      <td>371</td>\n",
       "      <td>-0.007770</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415262</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>-0.184476</td>\n",
       "      <td>371</td>\n",
       "      <td>-0.184476</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415263</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>0.122415</td>\n",
       "      <td>371</td>\n",
       "      <td>0.122415</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415264</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>371</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415265</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>468</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2443192</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>-0.023635</td>\n",
       "      <td>468</td>\n",
       "      <td>-0.023635</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2443193</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>-0.009448</td>\n",
       "      <td>468</td>\n",
       "      <td>-0.009448</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2443194</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>-0.002857</td>\n",
       "      <td>468</td>\n",
       "      <td>-0.002857</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2443195</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>468</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>lcd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2443196</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3494 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      asof_date  return_value new  benchmark_id  return_value old source  \\\n",
       "0    2020-01-31          0.001852           371          0.001852    lcd   \n",
       "1    2020-02-29         -0.007770           371         -0.007770    lcd   \n",
       "2    2020-03-31         -0.184476           371         -0.184476    lcd   \n",
       "3    2020-04-30          0.122415           371          0.122415    lcd   \n",
       "4    2020-05-31          0.011719           371          0.011719    lcd   \n",
       "...         ...               ...           ...               ...    ...   \n",
       "3489 2022-08-31          0.009380           468          0.009380    lcd   \n",
       "3490 2022-09-30         -0.023635           468         -0.023635    lcd   \n",
       "3491 2022-10-31         -0.009448           468         -0.009448    lcd   \n",
       "3492 2022-11-30         -0.002857           468         -0.002857    lcd   \n",
       "3493 2022-12-31         -0.008308           468         -0.008308    lcd   \n",
       "\n",
       "      type  ret_ts_id  matching  \n",
       "0      NaN    2415261      True  \n",
       "1      NaN    2415262      True  \n",
       "2      NaN    2415263      True  \n",
       "3      NaN    2415264      True  \n",
       "4      NaN    2415265      True  \n",
       "...    ...        ...       ...  \n",
       "3489   NaN    2443192      True  \n",
       "3490   NaN    2443193      True  \n",
       "3491   NaN    2443194      True  \n",
       "3492   NaN    2443195      True  \n",
       "3493   NaN    2443196      True  \n",
       "\n",
       "[3494 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872a4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390f809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa01c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce48556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1cec81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbaea0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3ab84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea9d6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463cd314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3290f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc74467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm_missing_returns.to_sql('benchmark_returns_ts', engine, if_exists='append', index=False)  # index=False prevents failure on trying to insert the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c48a26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635cc88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c422f20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9debf50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b469491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
